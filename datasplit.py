import matplotlib.pyplot as plt
import csv
import random
import argparse
import numpy as np
import json
import os
import torch
import torch.nn as nn
import clip
from PIL import Image
parser = argparse.ArgumentParser()
#annotated verb-object pairs data
parser.add_argument('--inputVO', type=str, default='data/ovpair.csv', help='input verb-object file') 
#below file is generated by resnet.py
# parser.add_argument('--inputOA', type=str, default='../data/object-embedding.csv', help='input object-embedding file') #object embedding이 들어있는 파일
# #저장할 파일 
# parser.add_argument('--train', type=str, default='../data/corpus-train.csv', help='output file')
# parser.add_argument('--test', type=str, default='../data/corpus-test.csv', help='output file')
opt = parser.parse_args()

random.seed(100)


with open('data/vo_dict.json', 'r') as vo: 
    vo_dict = json.load(vo)
# print(len(vo_dict),2222)

with open('data/ov_dict.json', 'r') as ov: 
    ov_dict = json.load(ov)
# print(len(ov_dict),3333)

object_list = list(ov_dict.keys())
random.shuffle(object_list)

print(len(object_list))
# test1 = []
# test2 = []
# test3 = []
# test4 = []
# test5 = []
###testset split###
test1 = object_list[:82]
test2 = object_list[128:210]
test3 = object_list[256:338]
test4 = object_list[384:466]
test5 = object_list[512:]

# print(len(test1))
# print(len(test2))
# print(len(test3))
# print(len(test4))
# print(len(test5))

###trainset split###
train1 = []
train2 = []
train3 = []
train4 = []
train5 = []

for object in object_list:
    if object not in test1:
        train1.append(object)
    if object not in test2:
        train2.append(object)
    if object not in test3:
        train3.append(object)
    if object not in test4:
        train4.append(object)
    if object not in test5:
        train5.append(object)


# print(len(train1))
# print(len(train2))
# print(len(train3))
# print(len(train4))
# print(len(train5))
train = [train1,train2,train3,train4,train5]
test = [test1,test2,test3,test4,test5]

# print(len(train))
# print(test1)





# with open('data/train_label.json', 'w+') as f: 
#     for i in train:
#         f.write(json.dumps(i)) #json 문자열로 변환
        
# with open('data/test_label.json', 'w+') as f: 
#     for i in test:
#         f.write(json.dumps(i)) #json 문자열로 변환


# print(len(train1))


###CLIP affordance 생성###
###train의 이미지 경로###
# label_path = {}
# with open('data/image_label.json') as data: #이거는 안보임 imagemet데이터에서 만듦
#     for line in data:
#         image_label = json.loads(line) #iamge_label => key : image_name, value : name
#     # print(image_label)

#     dir = 'ILSVRC2012_img_val/Images/imagenet' #이미지셋의 경로로 변경
#     for f in os.listdir(dir): #지정한 디렉토리 내의 모든 파일과 디렉토리 리스트를 리턴
#         obj = str(image_label[f]).lower()
#         if obj in train1:
#             if obj not in label_path:
#                 label_path[obj] = []
#             label_path[obj].append(f)

# with open('data/label_path.json', 'w+') as f: 
#     f.write(json.dumps(label_path)) #json 문자열로 변환


###갯수 체크###
# for label in label_path.keys():
#     if len(label_path[label]) != 50:
#         print(label)

#-----LOAD MODEL-----#
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("RN50") #ViT-B/32 #RN101 #RN50


###Train 이미지 임베딩 생성###
# label_embedding = {}
# with open('data/image_label.json') as data: #이거는 안보임 imagemet데이터에서 만듦
#     for line in data:
#         image_label = json.loads(line) #iamge_label => key : image_name, value : name
#     # print(image_label)

#     dir = 'ILSVRC2012_img_val/Images/imagenet' #이미지셋의 경로로 변경
#     for f in os.listdir(dir): #지정한 디렉토리 내의 모든 파일과 디렉토리 리스트를 리턴
#         obj = str(image_label[f]).lower()
#         if obj in train1:
#             if obj not in label_embedding:
#                 label_embedding[obj] = []
#             input_image = Image.open(os.path.join(dir, f))
#             input_tensor = preprocess(input_image)
#             input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model
#             # move the input and model to GPU for speed if available
#             if torch.cuda.is_available():
#                 input_batch = input_batch.to('cuda')
#                 model.to('cuda')
#                 #print(input_batch.shape)
#             with torch.no_grad():
#                 try:
#                     output = model.encode_image(input_batch) #이미지를 모델에 넣음
#                 except:
#                     print(os.path.join(dir, f))
#                 label_embedding[obj].append(output[0].tolist())



# with open('data/label_embedding.json', 'w+') as f: 
#     f.write(json.dumps(label_embedding)) #json 문자열로 변환



###Test 이미지 임베딩 생성###
label_embedding = {}
with open('data/image_label.json') as data: #이거는 안보임 imagemet데이터에서 만듦
    for line in data:
        image_label = json.loads(line) #iamge_label => key : image_name, value : name
    # print(image_label)

    dir = 'ILSVRC2012_img_val/Images/imagenet' #이미지셋의 경로로 변경
    for f in os.listdir(dir): #지정한 디렉토리 내의 모든 파일과 디렉토리 리스트를 리턴
        obj = str(image_label[f]).lower()
        if obj in test1:
            if obj not in label_embedding:
                label_embedding[obj] = []
            input_image = Image.open(os.path.join(dir, f))
            input_tensor = preprocess(input_image)
            input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model
            # move the input and model to GPU for speed if available
            if torch.cuda.is_available():
                input_batch = input_batch.to('cuda')
                model.to('cuda')
                #print(input_batch.shape)
            with torch.no_grad():
                try:
                    output = model.encode_image(input_batch) #이미지를 모델에 넣음
                except:
                    print(os.path.join(dir, f))
                label_embedding[obj].append(output[0].tolist())



with open('data/test_embedding.json', 'w+') as f: 
    f.write(json.dumps(label_embedding)) #json 문자열로 변환